{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60daea7d-da5e-48b7-8ee6-a189d1c66794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graf yükleniyor...\n",
      "Düğüm sayısı: 8371\n",
      "\n",
      "GCN modeli çalıştırılıyor...\n",
      "Epoch 50/200, Loss: 1.1161\n",
      "Epoch 100/200, Loss: 1.3572\n",
      "Epoch 150/200, Loss: 1.1465\n",
      "Epoch 200/200, Loss: 1.1186\n",
      "En iyi küme sayısı aranıyor (3-20 arası)...\n",
      "Seçilen küme sayısı: 20 (Score: 155946.5191)\n",
      "\n",
      "GCN_GNN Tamamlandı (2699.81 sn)\n",
      "Toplam Küme Sayısı: 20\n",
      "Embeddingler kaydedildi: community_results\\gcn_gnn_embeddings.csv\n",
      "\n",
      "GAT modeli çalıştırılıyor...\n",
      "Epoch 50/200, Loss: 16.8393\n",
      "Epoch 100/200, Loss: 14.3242\n",
      "Epoch 150/200, Loss: 2.6010\n",
      "Epoch 200/200, Loss: 1.5961\n",
      "En iyi küme sayısı aranıyor (3-20 arası)...\n",
      "Seçilen küme sayısı: 20 (Score: 183968.3589)\n",
      "\n",
      "GAT_GNN Tamamlandı (3187.02 sn)\n",
      "Toplam Küme Sayısı: 20\n",
      "Embeddingler kaydedildi: community_results\\gat_gnn_embeddings.csv\n",
      "\n",
      "İşlem tamamlandı.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "\n",
    "# --- GCN Model Tanımı ---\n",
    "class GCN_Community(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_dim=64, embedding_dim=32):\n",
    "        super(GCN_Community, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = GCNConv(hidden_dim, embedding_dim)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        # 1. Katman\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        # 2. Katman\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        # 3. Katman (Embedding Çıktısı)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# --- GAT Model Tanımı ---\n",
    "class GAT_Community(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_dim=64, embedding_dim=32, heads=4):\n",
    "        super(GAT_Community, self).__init__()\n",
    "        self.conv1 = GATConv(num_features, hidden_dim, heads=heads, dropout=0.6)\n",
    "        self.conv2 = GATConv(hidden_dim * heads, embedding_dim, heads=1, concat=False, dropout=0.6)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# --- Negatif Örnekleme (Loss fonksiyonu için) ---\n",
    "def negative_sampling(data, num_neg_samples=None):\n",
    "    num_nodes = data.num_nodes\n",
    "    num_edges = data.edge_index.size(1)\n",
    "    if num_neg_samples is None:\n",
    "        num_neg_samples = num_edges\n",
    "    \n",
    "    neg_edges = []\n",
    "    edge_set = set(map(tuple, data.edge_index.t().tolist()))\n",
    "    \n",
    "    while len(neg_edges) < num_neg_samples:\n",
    "        i = np.random.randint(0, num_nodes)\n",
    "        j = np.random.randint(0, num_nodes)\n",
    "        if i != j and (i, j) not in edge_set and (j, i) not in edge_set:\n",
    "            neg_edges.append([i, j])\n",
    "    \n",
    "    return torch.tensor(neg_edges, dtype=torch.long).t().to(data.edge_index.device)\n",
    "\n",
    "# --- Eğitim Fonksiyonu ---\n",
    "def train_gnn(model, data, optimizer, epochs=200):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        embeddings = model(data)\n",
    "        \n",
    "        # Reconstruction Loss\n",
    "        pos_edge_index = data.edge_index\n",
    "        neg_edge_index = negative_sampling(data)\n",
    "        \n",
    "        # Pozitif kenarların skoru (birbirine yakın olmalı)\n",
    "        pos_loss = -torch.log(\n",
    "            torch.sigmoid(\n",
    "                (embeddings[pos_edge_index[0]] * embeddings[pos_edge_index[1]]).sum(dim=1)\n",
    "            ) + 1e-15\n",
    "        ).mean()\n",
    "        \n",
    "        # Negatif kenarların skoru (birbirine uzak olmalı)\n",
    "        neg_loss = -torch.log(\n",
    "            1 - torch.sigmoid(\n",
    "                (embeddings[neg_edge_index[0]] * embeddings[neg_edge_index[1]]).sum(dim=1)\n",
    "            ) + 1e-15\n",
    "        ).mean()\n",
    "        \n",
    "        loss = pos_loss + neg_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "    return model\n",
    "\n",
    "# --- Clustering ---\n",
    "def cluster_embeddings(embeddings, num_clusters=None, max_clusters=20):\n",
    "    # Tensor kontrolü\n",
    "    if torch.is_tensor(embeddings):\n",
    "        embeddings_np = embeddings.detach().cpu().numpy()\n",
    "    else:\n",
    "        embeddings_np = embeddings\n",
    "    min_clusters=3\n",
    "    best_score = -1\n",
    "    best_k = min_clusters # Varsayılan başlangıç\n",
    "    \n",
    "    print(f\"En iyi küme sayısı aranıyor ({min_clusters}-{max_clusters} arası)...\")\n",
    "    \n",
    "    # Aramaya min_clusters'dan başla\n",
    "    search_range = range(min_clusters, min(max_clusters + 1, len(embeddings_np)))\n",
    "    \n",
    "    for k in search_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        labels = kmeans.fit_predict(embeddings_np)\n",
    "        \n",
    "        # Calinski-Harabasz kullanıyoruz (Daha yüksek k sayılarını sever)\n",
    "        score = calinski_harabasz_score(embeddings_np, labels)\n",
    "        \n",
    "        # İstersen skorları yazdırıp görebilirsin\n",
    "        # print(f\"k={k}, Score={score:.4f}\")\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "            \n",
    "    print(f\"Seçilen küme sayısı: {best_k} (Score: {best_score:.4f})\")\n",
    "    \n",
    "    # Final kümeleme\n",
    "    kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(embeddings_np)\n",
    "    \n",
    "    communities = {}\n",
    "    for label in np.unique(labels):\n",
    "        communities[int(label)] = np.where(labels == label)[0].tolist()\n",
    "    \n",
    "    return communities\n",
    "\n",
    "# --- YENİ: Embeddingleri Kaydetme Fonksiyonu ---\n",
    "def save_embeddings_to_csv(embeddings, node_list, algorithm_name):\n",
    "    \"\"\"\n",
    "    Embeddingleri CSV dosyasına kaydeder.\n",
    "    Format: NodeID, Emb_0, Emb_1, ..., Emb_N\n",
    "    \"\"\"\n",
    "    output_dir = \"community_results\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    filename = os.path.join(output_dir, f\"{algorithm_name.lower()}_embeddings.csv\")\n",
    "    \n",
    "    # Tensor kontrolü\n",
    "    if torch.is_tensor(embeddings):\n",
    "        embeddings_np = embeddings.detach().cpu().numpy()\n",
    "    else:\n",
    "        embeddings_np = embeddings_np\n",
    "\n",
    "    try:\n",
    "        with open(filename, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            \n",
    "            # Header yaz (NodeID, dim0, dim1...)\n",
    "            header = [\"NodeID\"] + [f\"dim_{i}\" for i in range(embeddings_np.shape[1])]\n",
    "            writer.writerow(header)\n",
    "            \n",
    "            # Her satırı yaz\n",
    "            for i, node_id in enumerate(node_list):\n",
    "                row = [node_id] + list(embeddings_np[i])\n",
    "                writer.writerow(row)\n",
    "                \n",
    "        print(f\"Embeddingler kaydedildi: {filename}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Embedding kaydetme hatası: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def save_communities_to_csv(communities, node_list, algorithm_name):\n",
    "    if not communities: return False\n",
    "    \n",
    "    output_dir = \"community_results\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    filename = os.path.join(output_dir, f\"{algorithm_name.lower()}_communities.csv\")\n",
    "    \n",
    "    try:\n",
    "        with open(filename, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            for comm_id, member_indices in communities.items():\n",
    "                # İndeksleri gerçek düğüm isimlerine çevir\n",
    "                real_members = [node_list[idx] for idx in member_indices]\n",
    "                writer.writerow(real_members)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Community CSV hatası: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def run_gnn_community_detection(G_nx, model_type=\"gcn\", epochs=200, embedding_dim=32):\n",
    "    print(f\"\\n{model_type.upper()} modeli çalıştırılıyor...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Düğüm sırasını sabitle (NetworkX node order)\n",
    "    # Bu liste, index (0,1,2) ile gerçek düğüm ismi (UserA, UserB) arasındaki eşleşmedir.\n",
    "    node_list = list(G_nx.nodes())\n",
    "    \n",
    "    data = from_networkx(G_nx)\n",
    "    \n",
    "    # Node feature yoksa derece (degree) bilgisini feature olarak kullan\n",
    "    if not hasattr(data, 'x') or data.x is None:\n",
    "        degrees = torch.tensor([G_nx.degree(node) for node in G_nx.nodes()], dtype=torch.float)\n",
    "        data.x = degrees.unsqueeze(1)\n",
    "    \n",
    "    num_features = data.x.size(1)\n",
    "    \n",
    "    if model_type.lower() == \"gcn\":\n",
    "        model = GCN_Community(num_features, hidden_dim=64, embedding_dim=embedding_dim)\n",
    "    elif model_type.lower() == \"gat\":\n",
    "        model = GAT_Community(num_features, hidden_dim=64, embedding_dim=embedding_dim)\n",
    "    else:\n",
    "        print(f\"Bilinmeyen model: {model_type}\")\n",
    "        return None, None, None\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    model = train_gnn(model, data, optimizer, epochs=epochs)\n",
    "    \n",
    "    # Embeddingleri al\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(data)\n",
    "    \n",
    "    # Kümele\n",
    "    communities = cluster_embeddings(embeddings)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # ÖNEMLİ: Embeddingleri de döndürüyoruz\n",
    "    return communities, embeddings, elapsed_time, node_list\n",
    "\n",
    "def main():\n",
    "    print(\"Graf yükleniyor...\")\n",
    "    try:\n",
    "        # Dosya adını kontrol et\n",
    "        if not os.path.exists(\"my.adjlist\"):\n",
    "            print(\"HATA: 'my.adjlist' dosyası bulunamadı!\")\n",
    "            return\n",
    "\n",
    "        G_nx = nx.read_adjlist(\"my.adjlist\")\n",
    "        if nx.is_directed(G_nx):\n",
    "            G_nx = G_nx.to_undirected()\n",
    "            \n",
    "        print(f\"Düğüm sayısı: {G_nx.number_of_nodes()}\")\n",
    "        \n",
    "        gnn_models = [\"gcn\", \"gat\"]\n",
    "        \n",
    "        for model_type in gnn_models:\n",
    "            # Fonksiyon artık 4 değer döndürüyor\n",
    "            communities, embeddings, elapsed_time, node_list = run_gnn_community_detection(\n",
    "                G_nx, \n",
    "                model_type=model_type,\n",
    "                epochs=200,\n",
    "                embedding_dim=32\n",
    "            )\n",
    "            \n",
    "            if communities:\n",
    "                algo_name = f\"{model_type.upper()}_GNN\"\n",
    "                \n",
    "                print(f\"\\n{algo_name} Tamamlandı ({elapsed_time:.2f} sn)\")\n",
    "                print(f\"Toplam Küme Sayısı: {len(communities)}\")\n",
    "                \n",
    "                # 1. Toplulukları Kaydet\n",
    "                save_communities_to_csv(communities, node_list, algo_name)\n",
    "                \n",
    "                # 2. Embeddingleri Kaydet (YENİ)\n",
    "                save_embeddings_to_csv(embeddings, node_list, algo_name)\n",
    "                \n",
    "        print(\"\\nİşlem tamamlandı.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Beklenmedik bir hata: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7194e1d6-7b2b-41c0-add9-56fc2ddd8e51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
