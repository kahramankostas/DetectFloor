{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc2ff757-be22-4522-8bca-a901e602f1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "İşleniyor: ./ValidationGeo\n",
      "================================================================================\n",
      "Bulunan dosyalar: 7\n",
      "\n",
      "--- edge_betweenness ---\n",
      "F1-Score: 0.4670 | Adjusted F1: 0.0047\n",
      "Küme Sayısı: 36 | Kat Sayısı: 13\n",
      "⚠️ Singleton oranı yüksek: 97.2%\n",
      "\n",
      "--- fast_greedy ---\n",
      "F1-Score: 0.0997 | Adjusted F1: 0.0997\n",
      "Küme Sayısı: 2 | Kat Sayısı: 13\n",
      "\n",
      "--- infomap ---\n",
      "F1-Score: 0.0551 | Adjusted F1: 0.0551\n",
      "Küme Sayısı: 1 | Kat Sayısı: 13\n",
      "\n",
      "--- label_propagation ---\n",
      "F1-Score: 0.0551 | Adjusted F1: 0.0551\n",
      "Küme Sayısı: 1 | Kat Sayısı: 13\n",
      "\n",
      "--- leiden ---\n",
      "F1-Score: 0.1113 | Adjusted F1: 0.1113\n",
      "Küme Sayısı: 3 | Kat Sayısı: 13\n",
      "\n",
      "--- louvain ---\n",
      "F1-Score: 0.0953 | Adjusted F1: 0.0953\n",
      "Küme Sayısı: 2 | Kat Sayısı: 13\n",
      "\n",
      "--- Node2Vec ---\n",
      "F1-Score: 0.6162 | Adjusted F1: 0.6162\n",
      "Küme Sayısı: 20 | Kat Sayısı: 13\n",
      "\n",
      "✅ ValidationGeo sonuçları kaydedildi: ./results/ValidationGeo\n",
      "\n",
      "================================================================================\n",
      "İşleniyor: ./ValidationWDE\n",
      "================================================================================\n",
      "Bulunan dosyalar: 7\n",
      "\n",
      "--- edge_betweenness ---\n",
      "F1-Score: 0.4670 | Adjusted F1: 0.0047\n",
      "Küme Sayısı: 36 | Kat Sayısı: 13\n",
      "⚠️ Singleton oranı yüksek: 97.2%\n",
      "\n",
      "--- fast_greedy ---\n",
      "F1-Score: 0.0997 | Adjusted F1: 0.0997\n",
      "Küme Sayısı: 2 | Kat Sayısı: 13\n",
      "\n",
      "--- infomap ---\n",
      "F1-Score: 0.0551 | Adjusted F1: 0.0551\n",
      "Küme Sayısı: 1 | Kat Sayısı: 13\n",
      "\n",
      "--- label_propagation ---\n",
      "F1-Score: 0.0993 | Adjusted F1: 0.0993\n",
      "Küme Sayısı: 2 | Kat Sayısı: 13\n",
      "\n",
      "--- leiden ---\n",
      "F1-Score: 0.1082 | Adjusted F1: 0.1082\n",
      "Küme Sayısı: 3 | Kat Sayısı: 13\n",
      "\n",
      "--- louvain ---\n",
      "F1-Score: 0.1082 | Adjusted F1: 0.1082\n",
      "Küme Sayısı: 3 | Kat Sayısı: 13\n",
      "\n",
      "--- Node2Vec ---\n",
      "F1-Score: 0.6162 | Adjusted F1: 0.6162\n",
      "Küme Sayısı: 20 | Kat Sayısı: 13\n",
      "\n",
      "✅ ValidationWDE sonuçları kaydedildi: ./results/ValidationWDE\n",
      "\n",
      "================================================================================\n",
      "İşleniyor: ./TrainingGeo\n",
      "================================================================================\n",
      "Bulunan dosyalar: 7\n",
      "\n",
      "--- edge_betweenness ---\n",
      "F1-Score: 0.7943 | Adjusted F1: 0.0056\n",
      "Küme Sayısı: 43 | Kat Sayısı: 13\n",
      "⚠️ Singleton oranı yüksek: 97.7%\n",
      "⚠️ Over-clustering: 3.3x fazla küme\n",
      "\n",
      "--- fast_greedy ---\n",
      "F1-Score: 0.1261 | Adjusted F1: 0.1261\n",
      "Küme Sayısı: 4 | Kat Sayısı: 13\n",
      "\n",
      "--- infomap ---\n",
      "F1-Score: 0.0260 | Adjusted F1: 0.0260\n",
      "Küme Sayısı: 1 | Kat Sayısı: 13\n",
      "\n",
      "--- label_propagation ---\n",
      "F1-Score: 1.0000 | Adjusted F1: 0.0000\n",
      "Küme Sayısı: 59 | Kat Sayısı: 13\n",
      "⚠️ Singleton oranı yüksek: 100.0%\n",
      "⚠️ Over-clustering: 4.5x fazla küme\n",
      "\n",
      "--- leiden ---\n",
      "F1-Score: 0.1439 | Adjusted F1: 0.1439\n",
      "Küme Sayısı: 5 | Kat Sayısı: 13\n",
      "\n",
      "--- louvain ---\n",
      "F1-Score: 0.0943 | Adjusted F1: 0.0943\n",
      "Küme Sayısı: 5 | Kat Sayısı: 13\n",
      "\n",
      "--- Node2Vec ---\n",
      "F1-Score: 0.8106 | Adjusted F1: 0.8106\n",
      "Küme Sayısı: 20 | Kat Sayısı: 13\n",
      "\n",
      "✅ TrainingGeo sonuçları kaydedildi: ./results/TrainingGeo\n",
      "\n",
      "================================================================================\n",
      "İşleniyor: ./TrainingWDE\n",
      "================================================================================\n",
      "Bulunan dosyalar: 7\n",
      "\n",
      "--- edge_betweenness ---\n",
      "F1-Score: 0.7943 | Adjusted F1: 0.0056\n",
      "Küme Sayısı: 43 | Kat Sayısı: 13\n",
      "⚠️ Singleton oranı yüksek: 97.7%\n",
      "⚠️ Over-clustering: 3.3x fazla küme\n",
      "\n",
      "--- fast_greedy ---\n",
      "F1-Score: 0.1261 | Adjusted F1: 0.1261\n",
      "Küme Sayısı: 4 | Kat Sayısı: 13\n",
      "\n",
      "--- infomap ---\n",
      "F1-Score: 0.0260 | Adjusted F1: 0.0260\n",
      "Küme Sayısı: 1 | Kat Sayısı: 13\n",
      "\n",
      "--- label_propagation ---\n",
      "F1-Score: 1.0000 | Adjusted F1: 0.0000\n",
      "Küme Sayısı: 59 | Kat Sayısı: 13\n",
      "⚠️ Singleton oranı yüksek: 100.0%\n",
      "⚠️ Over-clustering: 4.5x fazla küme\n",
      "\n",
      "--- leiden ---\n",
      "F1-Score: 0.1223 | Adjusted F1: 0.1223\n",
      "Küme Sayısı: 5 | Kat Sayısı: 13\n",
      "\n",
      "--- louvain ---\n",
      "F1-Score: 0.0818 | Adjusted F1: 0.0818\n",
      "Küme Sayısı: 4 | Kat Sayısı: 13\n",
      "\n",
      "--- Node2Vec ---\n",
      "F1-Score: 0.8106 | Adjusted F1: 0.8106\n",
      "Küme Sayısı: 20 | Kat Sayısı: 13\n",
      "\n",
      "✅ TrainingWDE sonuçları kaydedildi: ./results/TrainingWDE\n",
      "\n",
      "================================================================================\n",
      "Toplu Excel raporu oluşturuluyor...\n",
      "================================================================================\n",
      "\n",
      "✅ Toplu sonuçlar kaydedildi: ./results/TUM_SONUCLAR.xlsx\n",
      "\n",
      "================================================================================\n",
      "ÖZET TABLO (En İyi 10 Algoritma - Adjusted F1'e göre)\n",
      "================================================================================\n",
      "      Dataset   Algorithm  mapped_f1  adjusted_f1_score  num_clusters  singleton_ratio\n",
      "  TrainingWDE    Node2Vec   0.810603           0.810603            20             0.30\n",
      "  TrainingGeo    Node2Vec   0.810603           0.810603            20             0.30\n",
      "ValidationGeo    Node2Vec   0.616211           0.616211            20             0.05\n",
      "ValidationWDE    Node2Vec   0.616211           0.616211            20             0.05\n",
      "  TrainingGeo      leiden   0.143919           0.143919             5             0.00\n",
      "  TrainingWDE fast_greedy   0.126082           0.126082             4             0.00\n",
      "  TrainingGeo fast_greedy   0.126082           0.126082             4             0.00\n",
      "  TrainingWDE      leiden   0.122265           0.122265             5             0.00\n",
      "ValidationGeo      leiden   0.111254           0.111254             3             0.00\n",
      "ValidationWDE     louvain   0.108206           0.108206             3             0.00\n",
      "\n",
      "================================================================================\n",
      "İŞLEM TAMAMLANDI!\n",
      "================================================================================\n",
      "\n",
      "KLASÖR YAPISI:\n",
      "./results/\n",
      "  ├── ValidationGeo/\n",
      "  │   ├── algorithm1_metrics.json\n",
      "  │   ├── algorithm1_confusion_matrix.pdf\n",
      "  │   ├── algorithm1_cluster_analysis.json\n",
      "  │   └── ...\n",
      "  ├── ValidationWDE/\n",
      "  ├── TrainingGeo/\n",
      "  ├── TrainingWDE/\n",
      "  └── TUM_SONUCLAR.xlsx  ← Tüm sonuçlar burada!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import homogeneity_score, completeness_score, v_measure_score\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_ground_truth(json_file):\n",
    "    \"\"\"Loads ground truth labels from a JSON file.\"\"\"\n",
    "    with open(json_file, 'r') as f:\n",
    "        gt_data = json.load(f)\n",
    "    ap_to_floor = {int(k): v for k, v in gt_data.items()}\n",
    "    return ap_to_floor\n",
    "\n",
    "\n",
    "def load_clustering_result(csv_file):\n",
    "    \"\"\"Loads clustering results from a CSV file.\"\"\"\n",
    "    clusters = []\n",
    "    with open(csv_file, 'r') as f:\n",
    "        csv_reader = csv.reader(f)\n",
    "        for row in csv_reader:\n",
    "            cluster = [int(item.strip()) for item in row if item.strip() and item.strip().isdigit()]\n",
    "            if cluster:\n",
    "                clusters.append(cluster)\n",
    "    ap_to_cluster = {}\n",
    "    for cluster_id, aps in enumerate(clusters):\n",
    "        for ap in aps:\n",
    "            ap_to_cluster[ap] = cluster_id\n",
    "    return ap_to_cluster, clusters\n",
    "\n",
    "\n",
    "def map_clusters_to_floors(ap_to_floor, ap_to_cluster):\n",
    "    \"\"\"Maps clusters to floors (majority floor in the cluster becomes its label).\"\"\"\n",
    "    cluster_floor_counts = defaultdict(lambda: defaultdict(int))\n",
    "    common_aps = set(ap_to_floor.keys()) & set(ap_to_cluster.keys())\n",
    "    for ap in common_aps:\n",
    "        floor = ap_to_floor[ap]\n",
    "        cluster = ap_to_cluster[ap]\n",
    "        cluster_floor_counts[cluster][floor] += 1\n",
    "    cluster_to_floor = {}\n",
    "    for cluster, floor_counts in cluster_floor_counts.items():\n",
    "        cluster_to_floor[cluster] = max(floor_counts.items(), key=lambda x: x[1])[0]\n",
    "    return cluster_to_floor\n",
    "\n",
    "\n",
    "def create_true_pred_arrays(ap_to_floor, ap_to_cluster, cluster_to_floor):\n",
    "    \"\"\"Creates arrays of true and predicted labels for evaluation.\"\"\"\n",
    "    common_aps = sorted(set(ap_to_floor.keys()) & set(ap_to_cluster.keys()))\n",
    "    y_true = np.array([ap_to_floor[ap] for ap in common_aps])\n",
    "    y_pred_raw = np.array([ap_to_cluster[ap] for ap in common_aps])\n",
    "    y_pred_mapped = np.array([cluster_to_floor[ap_to_cluster[ap]] for ap in common_aps])\n",
    "    return common_aps, y_true, y_pred_raw, y_pred_mapped\n",
    "\n",
    "\n",
    "def calculate_cluster_quality_metrics(clusters, ap_to_floor):\n",
    "    \"\"\"Kümeleme kalitesini değerlendirir.\"\"\"\n",
    "    total_aps = sum(len(cluster) for cluster in clusters)\n",
    "    num_clusters = len(clusters)\n",
    "    num_unique_floors = len(set(ap_to_floor.values()))\n",
    "    \n",
    "    cluster_sizes = [len(cluster) for cluster in clusters]\n",
    "    avg_cluster_size = np.mean(cluster_sizes)\n",
    "    std_cluster_size = np.std(cluster_sizes)\n",
    "    \n",
    "    singleton_clusters = sum(1 for size in cluster_sizes if size == 1)\n",
    "    singleton_ratio = singleton_clusters / num_clusters if num_clusters > 0 else 0\n",
    "    \n",
    "    cluster_purities = []\n",
    "    for cluster in clusters:\n",
    "        if not cluster:\n",
    "            continue\n",
    "        floor_counts = defaultdict(int)\n",
    "        valid_count = 0\n",
    "        for ap in cluster:\n",
    "            if ap in ap_to_floor:\n",
    "                floor_counts[ap_to_floor[ap]] += 1\n",
    "                valid_count += 1\n",
    "        if valid_count > 0:\n",
    "            max_count = max(floor_counts.values())\n",
    "            purity = max_count / valid_count\n",
    "            cluster_purities.append(purity)\n",
    "    \n",
    "    avg_purity = np.mean(cluster_purities) if cluster_purities else 0\n",
    "    cluster_floor_ratio = num_clusters / num_unique_floors if num_unique_floors > 0 else float('inf')\n",
    "    \n",
    "    return {\n",
    "        'num_clusters': num_clusters,\n",
    "        'num_unique_floors': num_unique_floors,\n",
    "        'total_aps': total_aps,\n",
    "        'avg_cluster_size': avg_cluster_size,\n",
    "        'std_cluster_size': std_cluster_size,\n",
    "        'singleton_clusters': singleton_clusters,\n",
    "        'singleton_ratio': singleton_ratio,\n",
    "        'avg_cluster_purity': avg_purity,\n",
    "        'cluster_floor_ratio': cluster_floor_ratio,\n",
    "        'min_cluster_size': min(cluster_sizes) if cluster_sizes else 0,\n",
    "        'max_cluster_size': max(cluster_sizes) if cluster_sizes else 0\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_clustering(y_true, y_pred, prefix=\"\"):\n",
    "    \"\"\"Evaluates clustering performance and returns metrics.\"\"\"\n",
    "    results = {}\n",
    "    results[f\"{prefix}ari\"] = adjusted_rand_score(y_true, y_pred)\n",
    "    results[f\"{prefix}nmi\"] = normalized_mutual_info_score(y_true, y_pred)\n",
    "    results[f\"{prefix}homogeneity\"] = homogeneity_score(y_true, y_pred)\n",
    "    results[f\"{prefix}completeness\"] = completeness_score(y_true, y_pred)\n",
    "    results[f\"{prefix}v_measure\"] = v_measure_score(y_true, y_pred)\n",
    "    if prefix == \"mapped_\":\n",
    "        results[f\"{prefix}accuracy\"] = accuracy_score(y_true, y_pred)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            y_true, y_pred, average='weighted', zero_division=0\n",
    "        )\n",
    "        results[f\"{prefix}precision\"] = precision\n",
    "        results[f\"{prefix}recall\"] = recall\n",
    "        results[f\"{prefix}f1\"] = f1\n",
    "    return results\n",
    "\n",
    "\n",
    "def calculate_adjusted_score(mapped_f1, singleton_ratio, cluster_floor_ratio):\n",
    "    \"\"\"Over-clustering cezası eklenmiş adjusted score\"\"\"\n",
    "    if singleton_ratio > 0.5:\n",
    "        singleton_penalty = 0.5 * (1 - singleton_ratio)\n",
    "    else:\n",
    "        singleton_penalty = 1.0\n",
    "    \n",
    "    if cluster_floor_ratio > 5.0:\n",
    "        overclustering_penalty = max(0.1, 1.0 / (cluster_floor_ratio / 5.0))\n",
    "    elif cluster_floor_ratio > 2.0:\n",
    "        overclustering_penalty = max(0.5, 1.0 / (cluster_floor_ratio / 2.0))\n",
    "    else:\n",
    "        overclustering_penalty = 1.0\n",
    "    \n",
    "    adjusted_score = mapped_f1 * singleton_penalty * overclustering_penalty\n",
    "    return adjusted_score\n",
    "\n",
    "\n",
    "def generate_confusion_matrix(y_true, y_pred, output_file, title):\n",
    "    \"\"\"Generates and saves a confusion matrix plot.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(title)\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def analyze_clusters(clusters, ap_to_floor, output_dir):\n",
    "    \"\"\"Analyzes each cluster and visualizes floor distribution.\"\"\"\n",
    "    results = []\n",
    "    for cluster_id, aps in enumerate(clusters):\n",
    "        floor_counts = defaultdict(int)\n",
    "        valid_aps = 0\n",
    "        for ap in aps:\n",
    "            if ap in ap_to_floor:\n",
    "                floor_counts[ap_to_floor[ap]] += 1\n",
    "                valid_aps += 1\n",
    "        if not valid_aps:\n",
    "            continue\n",
    "        percentages = {floor: (count / valid_aps) * 100 for floor, count in floor_counts.items()}\n",
    "        dominant_floor = max(percentages.items(), key=lambda x: x[1]) if percentages else (None, 0)\n",
    "        results.append({\n",
    "            'cluster_id': cluster_id,\n",
    "            'total_aps': len(aps),\n",
    "            'valid_aps': valid_aps,\n",
    "            'floor_counts': dict(floor_counts),\n",
    "            'floor_percentages': percentages,\n",
    "            'dominant_floor': dominant_floor[0],\n",
    "            'dominant_percentage': dominant_floor[1]\n",
    "        })\n",
    "    \n",
    "    with open(os.path.join(output_dir, 'cluster_analysis.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=4)\n",
    "    return results\n",
    "\n",
    "\n",
    "def find_the_way(path, file_format, con=\"\"):\n",
    "    files_add = []\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            if file_format in file:\n",
    "                if con in file:\n",
    "                    files_add.append(os.path.join(r, file))\n",
    "    return files_add\n",
    "\n",
    "\n",
    "# ====== ANA DEĞERLENDİRME DÖNGÜSÜ ======\n",
    "paths = [\"./ValidationGeo\", \"./ValidationWDE\", \"./TrainingGeo\", \"./TrainingWDE\"]\n",
    "\n",
    "# Her path için toplu sonuçları tutacak liste\n",
    "all_metrics_list = []\n",
    "\n",
    "for p in paths:\n",
    "    path = f\"{p}/community_results\"\n",
    "    files_add = find_the_way(path, '_communities.csv')\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"İşleniyor: {p}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Bulunan dosyalar: {len(files_add)}\")\n",
    "\n",
    "    # BASİTLEŞTİRİLMİŞ KLASÖR YAPISI\n",
    "    # Artık sadece: results/{dataset_adi}/ altına her şey gidecek\n",
    "    dataset_name = p.replace('./', '').replace('/', '_')\n",
    "    main_output_dir = f'./results/{dataset_name}'\n",
    "    os.makedirs(main_output_dir, exist_ok=True)\n",
    "\n",
    "    for file in files_add:\n",
    "        # Algoritma adını dosya isminden çıkar\n",
    "        algo_name = os.path.basename(file).replace('_communities.csv', '')\n",
    "        \n",
    "        # 1. Setup file paths\n",
    "        gt_file = f'{p}/data_GT.json'\n",
    "        result_file = file\n",
    "        \n",
    "        # 2. Load data\n",
    "        ap_to_floor = load_ground_truth(gt_file)\n",
    "        ap_to_cluster, clusters = load_clustering_result(result_file)\n",
    "        cluster_to_floor = map_clusters_to_floors(ap_to_floor, ap_to_cluster)\n",
    "        \n",
    "        common_aps, y_true, y_pred_raw, y_pred_mapped = create_true_pred_arrays(\n",
    "            ap_to_floor, ap_to_cluster, cluster_to_floor\n",
    "        )\n",
    "        \n",
    "        # 3. Evaluate clustering\n",
    "        raw_results = evaluate_clustering(y_true, y_pred_raw, prefix=\"raw_\")\n",
    "        mapped_results = evaluate_clustering(y_true, y_pred_mapped, prefix=\"mapped_\")\n",
    "        \n",
    "        # 4. Küme kalite metrikleri\n",
    "        quality_metrics = calculate_cluster_quality_metrics(clusters, ap_to_floor)\n",
    "        \n",
    "        # 5. Adjusted score hesapla\n",
    "        adjusted_f1 = calculate_adjusted_score(\n",
    "            mapped_results['mapped_f1'],\n",
    "            quality_metrics['singleton_ratio'],\n",
    "            quality_metrics['cluster_floor_ratio']\n",
    "        )\n",
    "        \n",
    "        # Tüm sonuçları birleştir\n",
    "        all_results = {\n",
    "            'Dataset': dataset_name,\n",
    "            'Algorithm': algo_name,\n",
    "            **raw_results,\n",
    "            **mapped_results,\n",
    "            **quality_metrics,\n",
    "            'adjusted_f1_score': adjusted_f1\n",
    "        }\n",
    "        \n",
    "        # Toplu liste için ekle\n",
    "        all_metrics_list.append(all_results)\n",
    "        \n",
    "        # 6. Print Results\n",
    "        print(f\"\\n--- {algo_name} ---\")\n",
    "        print(f\"F1-Score: {mapped_results['mapped_f1']:.4f} | Adjusted F1: {adjusted_f1:.4f}\")\n",
    "        print(f\"Küme Sayısı: {quality_metrics['num_clusters']} | Kat Sayısı: {quality_metrics['num_unique_floors']}\")\n",
    "        \n",
    "        # Uyarılar\n",
    "        if quality_metrics['singleton_ratio'] > 0.3:\n",
    "            print(f\"⚠️ Singleton oranı yüksek: {quality_metrics['singleton_ratio']:.1%}\")\n",
    "        if quality_metrics['cluster_floor_ratio'] > 3:\n",
    "            print(f\"⚠️ Over-clustering: {quality_metrics['cluster_floor_ratio']:.1f}x fazla küme\")\n",
    "        \n",
    "        # 7. BASİTLEŞTİRİLMİŞ DOSYA KAYDETME\n",
    "        # Tüm dosyalar doğrudan main_output_dir altına, algoritma adıyla\n",
    "        \n",
    "        # JSON sonuçları\n",
    "        json_file = os.path.join(main_output_dir, f'{algo_name}_metrics.json')\n",
    "        with open(json_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(all_results, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "        # Confusion matrix\n",
    "        cm_file = os.path.join(main_output_dir, f'{algo_name}_confusion_matrix.pdf')\n",
    "        generate_confusion_matrix(y_true, y_pred_mapped, cm_file, \n",
    "                                 f'Confusion Matrix - {algo_name}')\n",
    "        \n",
    "        # Cluster analysis\n",
    "        analysis_file = os.path.join(main_output_dir, f'{algo_name}_cluster_analysis.json')\n",
    "        cluster_analysis = analyze_clusters(clusters, ap_to_floor, main_output_dir)\n",
    "        # Dosyayı taşı/yeniden adlandır\n",
    "        os.rename(os.path.join(main_output_dir, 'cluster_analysis.json'), analysis_file)\n",
    "    \n",
    "    print(f\"\\n✅ {dataset_name} sonuçları kaydedildi: {main_output_dir}\")\n",
    "\n",
    "# ====== TOPLU EXCEL RAPORU ======\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Toplu Excel raporu oluşturuluyor...\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "if all_metrics_list:\n",
    "    df_all = pd.DataFrame(all_metrics_list)\n",
    "    \n",
    "    # Sütun sırasını düzenle\n",
    "    important_cols = ['Dataset', 'Algorithm', 'mapped_f1', 'adjusted_f1_score', \n",
    "                     'mapped_accuracy', 'num_clusters', 'num_unique_floors', \n",
    "                     'singleton_ratio', 'cluster_floor_ratio']\n",
    "    other_cols = [c for c in df_all.columns if c not in important_cols]\n",
    "    df_all = df_all[important_cols + other_cols]\n",
    "    \n",
    "    # Excel'e kaydet\n",
    "    excel_file = './results/TUM_SONUCLAR.xlsx'\n",
    "    df_all.to_excel(excel_file, index=False)\n",
    "    print(f\"\\n✅ Toplu sonuçlar kaydedildi: {excel_file}\")\n",
    "    \n",
    "    # Özet tabloyu ekrana yazdır\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ÖZET TABLO (En İyi 10 Algoritma - Adjusted F1'e göre)\")\n",
    "    print(\"=\"*80)\n",
    "    summary = df_all[['Dataset', 'Algorithm', 'mapped_f1', 'adjusted_f1_score', \n",
    "                      'num_clusters', 'singleton_ratio']].copy()\n",
    "    summary = summary.sort_values('adjusted_f1_score', ascending=False).head(10)\n",
    "    print(summary.to_string(index=False))\n",
    "else:\n",
    "    print(\"❌ Hiçbir sonuç bulunamadı!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"İŞLEM TAMAMLANDI!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nKLASÖR YAPISI:\")\n",
    "print(\"./results/\")\n",
    "print(\"  ├── ValidationGeo/\")\n",
    "print(\"  │   ├── algorithm1_metrics.json\")\n",
    "print(\"  │   ├── algorithm1_confusion_matrix.pdf\")\n",
    "print(\"  │   ├── algorithm1_cluster_analysis.json\")\n",
    "print(\"  │   └── ...\")\n",
    "print(\"  ├── ValidationWDE/\")\n",
    "print(\"  ├── TrainingGeo/\")\n",
    "print(\"  ├── TrainingWDE/\")\n",
    "print(\"  └── TUM_SONUCLAR.xlsx  ← Tüm sonuçlar burada!\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30055245-db2c-4718-acb8-3ca737300748",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
